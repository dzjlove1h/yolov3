# YOLOv3 ğŸš€ by Ultralytics, GPL-3.0 license
"""
Auto-batch utils
"""

from copy import deepcopy

import numpy as np
import torch
from torch.cuda import amp

from utils.general import LOGGER, colorstr
from utils.torch_utils import profile


def check_train_batch_size(model, imgsz=640):
    # æ£€æŸ¥è®­ç»ƒçš„æ‰¹æ¬¡å¤§å°
    with amp.autocast():  # å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦ï¼ˆè‡ªåŠ¨è¿›è¡ŒåŠç²¾åº¦è®¡ç®—ï¼Œä»¥èŠ‚çœå†…å­˜å’ŒåŠ é€Ÿè®­ç»ƒï¼‰
        return autobatch(deepcopy(model).train(), imgsz)  # è®¡ç®—æœ€ä½³æ‰¹æ¬¡å¤§å°

def autobatch(model, imgsz=640, fraction=0.9, batch_size=16):
    # è‡ªåŠ¨ä¼°ç®—æœ€ä½³æ‰¹æ¬¡å¤§å°ï¼Œä»¥ä½¿ç”¨å¯ç”¨CUDAå†…å­˜çš„`fraction`æ¯”ä¾‹
    # ä½¿ç”¨ç¤ºä¾‹ï¼š
    #     import torch
    #     from utils.autobatch import autobatch
    #     model = torch.hub.load('ultralytics/yolov3', 'yolov3', autoshape=False)
    #     print(autobatch(model))

    prefix = colorstr('AutoBatch: ')  # è®¾ç½®å‰ç¼€ï¼Œç”¨äºæ—¥å¿—ä¿¡æ¯
    LOGGER.info(f'{prefix}Computing optimal batch size for --imgsz {imgsz}')  # æ‰“å°è®¡ç®—æ‰¹æ¬¡å¤§å°çš„æ—¥å¿—ä¿¡æ¯
    device = next(model.parameters()).device  # è·å–æ¨¡å‹æ‰€åœ¨çš„è®¾å¤‡
    if device.type == 'cpu':
        LOGGER.info(f'{prefix}CUDA not detected, using default CPU batch-size {batch_size}')  # å¦‚æœè®¾å¤‡æ˜¯CPUï¼Œä½¿ç”¨é»˜è®¤æ‰¹æ¬¡å¤§å°
        return batch_size

    d = str(device).upper()  # è·å–è®¾å¤‡å­—ç¬¦ä¸²è¡¨ç¤ºï¼ˆä¾‹å¦‚ 'CUDA:0'ï¼‰
    properties = torch.cuda.get_device_properties(device)  # è·å–CUDAè®¾å¤‡å±æ€§
    t = properties.total_memory / 1024 ** 3  # è®¾å¤‡æ€»å†…å­˜ï¼ˆä»¥GiBä¸ºå•ä½ï¼‰
    r = torch.cuda.memory_reserved(device) / 1024 ** 3  # è®¾å¤‡ä¸Šä¿ç•™çš„å†…å­˜ï¼ˆä»¥GiBä¸ºå•ä½ï¼‰
    a = torch.cuda.memory_allocated(device) / 1024 ** 3  # è®¾å¤‡ä¸Šå·²åˆ†é…çš„å†…å­˜ï¼ˆä»¥GiBä¸ºå•ä½ï¼‰
    f = t - (r + a)  # è®¡ç®—åœ¨ä¿ç•™å†…å­˜ä¸­çš„å¯ç”¨å†…å­˜
    LOGGER.info(f'{prefix}{d} ({properties.name}) {t:.2f}G total, {r:.2f}G reserved, {a:.2f}G allocated, {f:.2f}G free')  # æ‰“å°è®¾å¤‡å†…å­˜ä¿¡æ¯

    batch_sizes = [1, 2, 4, 8, 16]  # å®šä¹‰ä¸€ç»„æ‰¹æ¬¡å¤§å°
    try:
        img = [torch.zeros(b, 3, imgsz, imgsz) for b in batch_sizes]  # ä¸ºæ¯ä¸ªæ‰¹æ¬¡å¤§å°åˆ›å»ºä¸€ä¸ªé›¶å¼ é‡
        y = profile(img, model, n=3, device=device)  # ä½¿ç”¨profileå‡½æ•°æµ‹é‡æ¯ç§æ‰¹æ¬¡å¤§å°çš„å†…å­˜ä½¿ç”¨æƒ…å†µ
    except Exception as e:
        LOGGER.warning(f'{prefix}{e}')  # æ•è·å¼‚å¸¸å¹¶æ‰“å°è­¦å‘Šä¿¡æ¯

    y = [x[2] for x in y if x]  # æå–å†…å­˜ä½¿ç”¨æƒ…å†µï¼ˆç¬¬äºŒä¸ªç´¢å¼•ï¼‰
    batch_sizes = batch_sizes[:len(y)]  # æˆªå–ä¸å†…å­˜ä½¿ç”¨æƒ…å†µç›¸åŒ¹é…çš„æ‰¹æ¬¡å¤§å°
    p = np.polyfit(batch_sizes, y, deg=1)  # å¯¹æ‰¹æ¬¡å¤§å°å’Œå†…å­˜ä½¿ç”¨æƒ…å†µè¿›è¡Œä¸€æ¬¡å¤šé¡¹å¼æ‹Ÿåˆ
    b = int((f * fraction - p[1]) / p[0])  # æ ¹æ®æ‹Ÿåˆç»“æœè®¡ç®—æœ€ä½³æ‰¹æ¬¡å¤§å°
    LOGGER.info(f'{prefix}Using batch-size {b} for {d} {t * fraction:.2f}G/{t:.2f}G ({fraction * 100:.0f}%)')  # æ‰“å°æœ€ä½³æ‰¹æ¬¡å¤§å°ä¿¡æ¯
    return b  # è¿”å›è®¡ç®—å‡ºçš„æœ€ä½³æ‰¹æ¬¡å¤§å°
